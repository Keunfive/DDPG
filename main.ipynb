{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 30)           0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          3968        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          16512       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 25)           3225        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,217\n",
      "Trainable params: 40,217\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Assets written to: model_storage/DDQN_spline_1_1_episode_50\\assets\n",
      "INFO:tensorflow:Assets written to: model_storage/DDQN_spline_1_1_episode_100\\assets\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_65344\\47970534.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KEUNOH Lim\\vscodeprojects\\Mesh_v0704\\Meshpkg\\Env\\Action.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(model, volume_mesh, epsilon, num_iter)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                     tf.reshape(tf.one_hot(action[(j + 1) % p.surf_length] % 5, 5), [1,-1]) ], axis = 1)], axis = 1))\n\u001b[0;32m     76\u001b[0m                 \u001b[1;31m#########################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                     \u001b[0mtxt_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\n \\n --------------------Iteration [{m+1}]------------------------ \\n \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mtxt_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'node{j}: ({action[j - 1]})->({action[j]})<-({action[(j + 1) % p.surf_length]}) '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mstate_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_input_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0maction_neighbor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_neighbor_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\startgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\startgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1397\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\startgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   4000\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4001\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4002\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4003\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4004\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4005\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4006\u001b[0m       _result = _dispatcher_for_floor_mod(\n\u001b[0;32m   4007\u001b[0m           (x, y, name,), None)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import Meshpkg as mp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\"Parameter 정의\"\n",
    "p = mp.params\n",
    "\n",
    "\"Seed 설정\"\n",
    "seed = 42\n",
    "mp.Initialize.my_seed.my_seed_everywhere(42)\n",
    "\n",
    "\"Episode 수\" \n",
    "n_episodes = 1000\n",
    "\n",
    "\"model, target model(Double DQN) 정의\"\n",
    "model = mp.Initialize.model_definition.NNmodel().dense_multi()\n",
    "\n",
    "model_target = keras.models.clone_model(model)\n",
    "model_target.set_weights(model.get_weights())\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\"Replay_memory 정의\"\n",
    "replay_memory = deque(maxlen = p.buffer_size)\n",
    "\n",
    "\"Inference 주기\"\n",
    "episode_inference = 5\n",
    "\n",
    "\"Neural Network model 저장 주기, 저장 여부\"\n",
    "episode_save = 50\n",
    "save_model = True\n",
    "\n",
    "\"Episode - reward list/ Time initialize\"\n",
    "reward_list = [ ]\n",
    "reward_inf_list = [ ]\n",
    "start = time.time()\n",
    "\n",
    "for episode in range(1, n_episodes+1): \n",
    "    \n",
    "    s = mp.Env.Step.step_class()\n",
    "    state = s.reset()\n",
    "    step_ended = 0\n",
    "    # step_bar = tqdm(range(1, p.num_layer+1), desc = f'< Episode: {episode} > Steps' , leave = True, maxinterval = 0.1, position = 1)\n",
    "    reward_episode = 0\n",
    "    epsilon = max(((p.epsilon_start)**episode), p.epsilon_min) # epsilon 0.01 도달 까지 4603 필요\n",
    "    for step in range(1, p.num_layer+1):\n",
    "        _, actions = mp.Env.Action.get_action(model, s.volume_mesh, epsilon)\n",
    "        next_state, reward, done, info, steps =  s.step_func(actions, step, episode)\n",
    "        replay_memory.append((state, actions, reward, next_state, done, steps))\n",
    "        state = next_state\n",
    "        reward_episode += np.average(reward)\n",
    "        if any(done) == 1:\n",
    "            step_ended = step\n",
    "            reward_list.append(reward_episode)\n",
    "            \n",
    "            with open(\"episode_step_record.txt\", 'a') as epistep_file:\n",
    "                epistep_file.write(f' \\n<episode: {episode}> Step ended: {step_ended} ')\n",
    "                if episode == 1:\n",
    "                    end1 = start\n",
    "                end2 = time.time()\n",
    "                epi_time = str(datetime.timedelta(seconds= (end2 - end1)))\n",
    "                short1 = epi_time.split(\".\")[0]\n",
    "                total_time = str(datetime.timedelta(seconds= (end2 - start)))\n",
    "                short2 = total_time.split(\".\")[0]\n",
    "                epistep_file.write(f\"  Time per episode: {short1} (Total: {short2})\\n\") # epi 시간, 누적시간 출력\n",
    "                end1 = end2\n",
    "                \n",
    "            if step_ended != p.num_layer:\n",
    "                replay_memory = mp.Train.replay_penalty.penalty_reward(replay_memory, info, step_ended, 3, 3)\n",
    "            break\n",
    "    # step_bar.close()\n",
    "    \"replay memory 다 차면, episode 끝나고 model training 시작\"\n",
    "    if len(replay_memory) == p.buffer_size:\n",
    "        loss_mean, state_new, next_state_new, Q_values, target_Q_values = mp.Train.model_training.training_step_mean_DDQN(model, model_target, replay_memory)\n",
    "        \n",
    "    \"episode (episode_inference)회마다 Inference\"\n",
    "    if episode % (episode_inference) == 0:\n",
    "        volume_mesh_inf, reward_inf_mean = mp.Inference.inference.inference_step(model, episode)\n",
    "        mp.Inference.render.render(volume_mesh_inf, episode)\n",
    "        reward_inf_list.append(reward_inf_mean)\n",
    "\n",
    "    \"episode (episode_target)회마다 Target model update\"\n",
    "    if episode % (p.episode_target) == 0:\n",
    "        model_target.set_weights(model.get_weights())\n",
    "\n",
    "    \"episode (episode_save)회마다 model, replay memory, episode-reward 저장\"\n",
    "    if (episode % (episode_save) == 0) and (save_model):\n",
    "        model.save(f'model_storage/DDQN_{p.mesh_name}_episode_{episode}')\n",
    "        \n",
    "        mp.Inference.graph.graph_plot().createFolder('replay_memory')\n",
    "        with open(f'replay_memory/replay_memory_{episode}.p', 'wb') as fr:    \n",
    "            pickle.dump(replay_memory, fr)\n",
    "            \n",
    "        mp.Inference.graph.graph_plot().Episode_Reward_train_plot(reward_list, episode)\n",
    "        mp.Inference.graph.graph_plot().Episode_Reward_inf_plot(reward_inf_list, episode)\n",
    "\n",
    "print ('Finish at: ',str(datetime.timedelta(seconds= (time.time() - start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 30)           0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          3968        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          16512       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 25)           3225        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,217\n",
      "Trainable params: 40,217\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Assets written to: model_storage/DDQN_spline_1_1_episode_150\\assets\n",
      "INFO:tensorflow:Assets written to: model_storage/DDQN_spline_1_1_episode_200\\assets\n",
      "INFO:tensorflow:Assets written to: model_storage/DDQN_spline_1_1_episode_250\\assets\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import Meshpkg as mp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\"Parameter 정의\"\n",
    "p = mp.params\n",
    "\n",
    "\"Seed 설정\"\n",
    "seed = 42\n",
    "mp.Initialize.my_seed.my_seed_everywhere(42)\n",
    "\n",
    "\"Episode 수\"\n",
    "start_episode = 100\n",
    "n_episodes = 650\n",
    "\n",
    "\"model, target model(Double DQN) 정의\"\n",
    "model = tf.keras.models.load_model(f'model_storage/DDQN_{p.mesh_name}_episode_{start_episode}')\n",
    "\n",
    "\n",
    "model_target = keras.models.clone_model(model)\n",
    "model_target.set_weights(model.get_weights())\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\"Replay_memory 정의\"\n",
    "with open(f'replay_memory/replay_memory_{start_episode}.p', 'rb') as fr:  \n",
    "    replay_memory = pickle.load(fr)\n",
    "\n",
    "\"Inference 주기\"\n",
    "episode_inference = 5\n",
    "\n",
    "\"Neural Network model 저장 주기, 저장 여부\"\n",
    "episode_save = 50\n",
    "save_model = True\n",
    "\n",
    "\"Episode - reward list/ Time initialize\"\n",
    "with open(f'Episode_reward_train/reward_epi_{start_episode}.p', 'rb') as fe:     \n",
    "    reward_list = pickle.load(fe)\n",
    "##\n",
    "with open(f'Episode_reward_inf/reward_epi_{start_episode}.p', 'rb') as fei:     \n",
    "    reward_inf_list = pickle.load(fei)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for episode in range(start_episode+1, n_episodes+1): \n",
    "    \n",
    "    s = mp.Env.Step.step_class()\n",
    "    state = s.reset()\n",
    "    step_ended = 0\n",
    "    # step_bar = tqdm(range(1, p.num_layer+1), desc = f'< Episode: {episode} > Steps' , leave = True, maxinterval = 0.1, position = 1)\n",
    "    reward_episode = 0\n",
    "    epsilon = max(((p.epsilon_start)**episode), p.epsilon_min) # epsilon 0.01 도달 까지 4603 필요\n",
    "    for step in range(1, p.num_layer+1):\n",
    "        _, actions = mp.Env.Action.get_action(model, s.volume_mesh, epsilon)\n",
    "        next_state, reward, done, info, steps =  s.step_func(actions, step, episode)\n",
    "        replay_memory.append((state, actions, reward, next_state, done, steps))\n",
    "        state = next_state\n",
    "        reward_episode += np.average(reward)\n",
    "        if any(done) == 1:\n",
    "            step_ended = step\n",
    "            reward_list.append(reward_episode)\n",
    "            \n",
    "            with open(\"Episode_Step_record.txt\", 'a') as epistep_file:\n",
    "                epistep_file.write(f' \\n<episode: {episode}> Step ended: {step_ended} ')\n",
    "                if episode == start_episode+1:\n",
    "                    end1 = start\n",
    "                end2 = time.time()\n",
    "                epi_time = str(datetime.timedelta(seconds= (end2 - end1)))\n",
    "                short1 = epi_time.split(\".\")[0]\n",
    "                total_time = str(datetime.timedelta(seconds= (end2 - start)))\n",
    "                short2 = total_time.split(\".\")[0]\n",
    "                epistep_file.write(f\"  Time per episode: {short1} (Total: {short2})\\n\") # epi 시간, 누적시간 출력\n",
    "                end1 = end2\n",
    "                \n",
    "            if step_ended != p.num_layer:\n",
    "                replay_memory = mp.Train.replay_penalty.penalty_reward(replay_memory, info, step_ended, 3, 3)\n",
    "            break\n",
    "    # step_bar.close()\n",
    "    \"replay memory 다 차면, episode 끝나고 model training 시작\"\n",
    "    if len(replay_memory) == p.buffer_size:\n",
    "        loss_mean, state_new, next_state_new, Q_values, target_Q_values = mp.Train.model_training.training_step_mean_DDQN(model, model_target, replay_memory)\n",
    "        \n",
    "    \"episode (episode_inference)회마다 Inference\"\n",
    "    if episode % (episode_inference) == 0:\n",
    "        volume_mesh_inf, reward_inf_mean = mp.Inference.inference.inference_step(model, episode)\n",
    "        mp.Inference.render.render(volume_mesh_inf, episode)\n",
    "        reward_inf_list.append(reward_inf_mean)\n",
    "    \"episode (episode_target)회마다 Target model update\"\n",
    "    if episode % (p.episode_target) == 0:\n",
    "        # target model에 weight 그대로 복사\n",
    "        # model_target.set_weights(model.get_weights())\n",
    "        \n",
    "        # target model에 \"tau\"만큼만 weight 복사\n",
    "        mp.Train.target_update.soft_update(model_target.variables, model.variables, p.tau)\n",
    "    \"episode (episode_save)회마다 model, replay memory, episode-reward 저장\"\n",
    "    if (episode % (episode_save) == 0) and (save_model):\n",
    "        model.save(f'model_storage/DDQN_{p.mesh_name}_episode_{episode}')\n",
    "        \n",
    "        mp.Inference.graph.graph_plot().createFolder('replay_memory')\n",
    "        with open(f'replay_memory/replay_memory_{episode}.p', 'wb') as fr:    \n",
    "            pickle.dump(replay_memory, fr)\n",
    "            \n",
    "        mp.Inference.graph.graph_plot().Episode_Reward_train_plot(reward_list, episode)\n",
    "        mp.Inference.graph.graph_plot().Episode_Reward_inf_plot(reward_inf_list, episode)\n",
    "\n",
    "\n",
    "print ('Finish at: ',str(datetime.timedelta(seconds= (time.time() - start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Meshpkg.Train' has no attribute 'target_update'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mMeshpkg\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mp\u001b[39m.\u001b[39;49mTrain\u001b[39m.\u001b[39;49mtarget_update\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Meshpkg.Train' has no attribute 'target_update'"
     ]
    }
   ],
   "source": [
    "import Meshpkg as mp\n",
    "mp.Train.target_update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
